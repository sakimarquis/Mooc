{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - Neural networks - Part B (20 points)\n",
    "## Gradient descent for an artifical neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by *Brenden Lake* and *Todd Gureckis*  \n",
    "Computational Cognitive Modeling  \n",
    "NYU class webpage: https://brendenlake.github.io/CCM-site/  \n",
    "email to course instructors: instructors-ccm-spring2020@nyuccl.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "This homework is due before midnight on Monday Feb. 24, 2020.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment implements the gradient descent algorithm for a simple artificial neuron. As covered in lecture, the neuron will learn to compute logical OR. The neuron model and logical OR are shown below, for inputs $x_0$ and $x_1$ and target output $y$.\n",
    "\n",
    "<img src=\"images/nn_OR.jpeg\" style=\"width: 350px;\"/>\n",
    "\n",
    "This assignment requires some basic PyTorch skill. You can review your notes from lab and also two basic [PyTorch tutorials](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), \"What is PyTorch?\" and \"Autograd\", which should have the basics you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create `torch.tensor` objects for representing the data matrix `D` with targets `Y`. Each row of `D` is a different data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "D = np.zeros((4,2),dtype=float)\n",
    "D[0,:] = [0.,0.]\n",
    "D[1,:] = [0.,1.]\n",
    "D[2,:] = [1.,0.]\n",
    "D[3,:] = [1.,1.]\n",
    "D = torch.tensor(D,dtype=torch.float)\n",
    "Y = torch.tensor([0.,1.,1.,1.])\n",
    "N = D.shape[0] # number of input patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artificial neuron operates as follows. Given an input vector $x$, the net input ($\\textbf{net}$) to the neuron is computed as follows\n",
    "\n",
    "$$ \\textbf{net} = \\sum_i x_i w_i + b,$$\n",
    "\n",
    "for weights $w_i$ and bias $b$. The activation function $g(\\textbf{net})$ is the logistic function\n",
    "\n",
    "$$ g(\\textbf{net}) = \\frac{1}{1+e^{-\\textbf{net}}},$$\n",
    "\n",
    "which is used to compute the predicted output $\\hat{y} = g(\\textbf{net})$. Finally, the loss (squared error) for a particular pattern $x$ is defined as \n",
    "\n",
    "$$ E(w,b) = (\\hat{y}-y)^2,$$\n",
    "\n",
    "where the target output is $y$. **Your main task is to manually compute the gradients of the loss $E$ with respect to the neuron parameters:**\n",
    "\n",
    "$$\\frac{\\partial E(w,b)}{\\partial w}, \\frac{\\partial E(w,b)}{\\partial b}.$$\n",
    "\n",
    "By manually, we mean to program the gradient computation directly, using the formulas discussed in class. This is in contrast to using PyTorch's `autograd` (Automatric differentiation) that computes the gradient automatically, as discussed in class, lab, and in the PyTorch tutorial (e.g., `loss.backward()`). First, let's write the activation function and the loss in PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_logistic(net):\n",
    "    return 1. / (1.+torch.exp(-net))\n",
    "\n",
    "def loss(yhat,y):\n",
    "    return (yhat-y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll also write two functions for examining the internal operations of the neuron, and the gradients of its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_forward(x,yhat,y):\n",
    "    # Examine network's prediction for input x\n",
    "    print(' Input: ',end='')\n",
    "    print(x.numpy())\n",
    "    print(' Output: ' + str(round(yhat.item(),3)))\n",
    "    print(' Target: ' + str(y.item()))\n",
    "\n",
    "def print_grad(grad_w,grad_b):\n",
    "    # Examine gradients\n",
    "    print('  d_loss / d_w = ',end='')\n",
    "    print(grad_w)\n",
    "    print('  d_loss / d_b = ',end='')\n",
    "    print(grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's dive in and begin the implementation of stochastic gradient descent. We'll initialize our parameters $w$ and $b$ randomly, and proceed through a series of epochs of training. Each epoch involves visiting the four training patterns in random order, and updating the parameters after each presentation of an input pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 1 (10 points) </h3>\n",
    "<br>\n",
    "In the code below, fill in code to manually compute the gradient in closed form.\n",
    "    <ul>\n",
    "        <li>See lecture slides for the equation for the gradient for the weights w.</li>\n",
    "        <li>Derive (or reason) to get the equation for the gradient for bias b.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 2 (5 points) </h3>\n",
    "<br>\n",
    "In the code below, fill in code for the weight and bias update rule for gradient descent.\n",
    "</div>\n",
    "\n",
    "After completing the code, run it to compare **your gradients** with the **ground-truth computed by PyTorch.** Also, you can check the neuron's performance at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "#     Although you will implement gradient descent manually, let's set requires_grad=True\n",
    "#     anyway so PyTorch will track the gradient too, and we can compare your gradient with PyTorch's.\n",
    "w = torch.rand(2,requires_grad=True) # [size 2] tensor\n",
    "b = torch.rand(1,requires_grad=True) # [size 1] tensor\n",
    "\n",
    "alpha = 0.05 # learning rate\n",
    "nepochs = 2000 # number of epochs\n",
    "\n",
    "track_error = []\n",
    "verbose = True\n",
    "for e in range(nepochs): # for each epoch\n",
    "    error_epoch = 0. # sum loss across the epoch\n",
    "    perm = np.random.permutation(N)\n",
    "    for p in perm: # visit data points in random order\n",
    "        x = D[p,:] # input pattern\n",
    "        \n",
    "        # compute output of neuron\n",
    "        net = torch.dot(x,w)+b\n",
    "        yhat = g_logistic(net)\n",
    "        \n",
    "        # compute loss\n",
    "        y = Y[p]\n",
    "        myloss = loss(yhat,y)\n",
    "        error_epoch += myloss.item()\n",
    "        \n",
    "        # print output if this is the last epoch\n",
    "        if (e == nepochs-1):\n",
    "            print(\"Final result:\")\n",
    "            print_forward(x,yhat,y)\n",
    "            print(\"\")\n",
    "\n",
    "        # Compute the gradient manually\n",
    "        if verbose:\n",
    "            print('Compute the gradient manually')\n",
    "            print_forward(x,yhat,y)\n",
    "        with torch.no_grad():\n",
    "            # TODO : YOUR GRADIENT CODE GOES HERE\n",
    "            #  two lines of the form\n",
    "            #    w_grad = ...    ([size 2] PyTorch tensor)\n",
    "            #    b_grad = ...    ([size 1] PyTorch tensor)\n",
    "            #  make sure to inclose your code in the \"with torch.no_grad()\" wrapper,\n",
    "            #   otherwise PyTorch will try to track the \"gradient\" of the gradient computation, which we don't want.\n",
    "            raise Exception('Replace with your code.')                      \n",
    "        if verbose: print_grad(w_grad.numpy(),b_grad.numpy())\n",
    "\n",
    "        # Compute the gradient with PyTorch and compre with manual values\n",
    "        if verbose: print('Compute the gradient using PyTorch .backward()')\n",
    "        myloss.backward()\n",
    "        if verbose:\n",
    "            print_grad(w.grad.numpy(),b.grad.numpy())\n",
    "            print(\"\")\n",
    "        w.grad.zero_() # clear PyTorch's gradient\n",
    "        b.grad.zero_()\n",
    "        \n",
    "        # Parameter update with gradient descent\n",
    "        with torch.no_grad():\n",
    "            # TODO : YOUR PARAMETER UPDATE CODE GOES HERE\n",
    "            #  two lines of the form:\n",
    "            #    w -=   ....\n",
    "            #    b -=   ....\n",
    "            raise Exception('Replace with your code.')\n",
    "            \n",
    "    if verbose==True: verbose=False\n",
    "    track_error.append(error_epoch)\n",
    "    if e % 50 == 0:\n",
    "        print(\"epoch \" + str(e) + \"; error=\" +str(round(error_epoch,3)))\n",
    "    \n",
    "# track output of gradient descent\n",
    "plt.figure()\n",
    "plt.clf()\n",
    "plt.plot(track_error)\n",
    "plt.title('stochastic gradient descent (logistic activation)')\n",
    "plt.ylabel('error for epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's change the activation function to \"tanh\" from the \"logistic\" function, such that $g(\\textbf{net}) = \\tanh(\\textbf{net})$. Here is an implementation of tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_tanh(x):\n",
    "    return (torch.exp(x) - torch.exp(-x))/(torch.exp(x) + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of the tanh function is as follows:\n",
    "\n",
    "$$\\frac{\\partial g(\\textbf{net})}{\\partial \\textbf{net}}= \\frac{\\partial \\tanh(\\textbf{net})}{\\partial \\textbf{net}} = 1.0 - (\\tanh(\\textbf{net}))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 3 (5 points) </h3>\n",
    "<br>\n",
    "Just as before, fill in the missing code fragments for implementing gradient descent. This time we are using the tanh activation function. Be sure to change your gradient calculation to reflect the new activation function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "#     Although you will implement gradient descent manually, let's set requires_grad=True\n",
    "#     anyway so PyTorch will track the gradient too, and we can compare your gradient with PyTorch's.\n",
    "w = torch.rand(2,requires_grad=True) # [size 2] tensor\n",
    "b = torch.rand(1,requires_grad=True) # [size 1] tensor\n",
    "\n",
    "alpha = 0.05 # learning rate\n",
    "nepochs = 2000 # number of epochs\n",
    "\n",
    "track_error = []\n",
    "verbose = True\n",
    "for e in range(nepochs): # for each epoch\n",
    "    error_epoch = 0. # sum loss across the epoch\n",
    "    perm = np.random.permutation(N)\n",
    "    for p in perm: # visit data points in random order\n",
    "        x = D[p,:] # input pattern\n",
    "        \n",
    "        # compute output of neuron\n",
    "        net = torch.dot(x,w)+b\n",
    "        yhat = g_tanh(net)\n",
    "        \n",
    "        # compute loss\n",
    "        y = Y[p]\n",
    "        myloss = loss(yhat,y)\n",
    "        error_epoch += myloss.item()\n",
    "        \n",
    "        # print output if this is the last epoch\n",
    "        if (e == nepochs-1):\n",
    "            print(\"Final result:\")\n",
    "            print_forward(x,yhat,y)\n",
    "            print(\"\")\n",
    "\n",
    "        # Compute the gradient manually\n",
    "        if verbose:\n",
    "            print('Compute the gradient manually')\n",
    "            print_forward(x,yhat,y)\n",
    "        with torch.no_grad():\n",
    "            # TODO : YOUR GRADIENT CODE GOES HERE\n",
    "            #  two lines of the form\n",
    "            #    w_grad = ...    ([size 2] PyTorch tensor)\n",
    "            #    b_grad = ...    ([size 1] PyTorch tensor)\n",
    "            #  make sure to inclose your code in the \"with torch.no_grad()\" wrapper,\n",
    "            #   otherwise PyTorch will try to track the \"gradient\" of the graident computation, which we don't want.\n",
    "            raise Exception('Replace with your code.')                       \n",
    "        if verbose: print_grad(w_grad.numpy(),b_grad.numpy())\n",
    "\n",
    "        # Compute the gradient with PyTorch and compre with manual values\n",
    "        if verbose: print('Compute the gradient using PyTorch .backward()')\n",
    "        myloss.backward()\n",
    "        if verbose:\n",
    "            print_grad(w.grad.numpy(),b.grad.numpy())\n",
    "            print(\"\")\n",
    "        w.grad.zero_() # clear PyTorch's gradient\n",
    "        b.grad.zero_()\n",
    "        \n",
    "        # Parameter update with gradient descent\n",
    "        with torch.no_grad():\n",
    "            # TODO : YOUR PARAMETER UPDATE CODE GOES HERE\n",
    "            #  two lines of the form:\n",
    "            #    w -=   ....\n",
    "            #    b -=   ....\n",
    "            raise Exception('Replace with your code.')\n",
    "            \n",
    "    if verbose==True: verbose=False\n",
    "    track_error.append(error_epoch)\n",
    "    if e % 50 == 0:\n",
    "        print(\"epoch \" + str(e) + \"; error=\" +str(round(error_epoch,3)))\n",
    "    \n",
    "# track output of gradient descent\n",
    "plt.figure()\n",
    "plt.clf()\n",
    "plt.plot(track_error)\n",
    "plt.title('stochastic gradient descent (tanh activation)')\n",
    "plt.ylabel('error for epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning in homework\n",
    "\n",
    "When you are finished with this notebook. Save your work in order to turn it in.  To do this select *File*->*Download As...*->*PDF*.\n",
    "\n",
    "<img src=\"images/save-pdf.png\" width=\"300\">\n",
    "\n",
    "You can turn in your assignments using NYU Classes webpage for the course (available on https://home.nyu.edu). **Make sure you complete all parts (A-E) of this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
