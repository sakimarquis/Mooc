{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "from game import Game\n",
    "from teacher import Teacher\n",
    "from agent import Qlearner, SARSAlearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the learning agent. We will use SARSA for now. All Q-values are initialized to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SARSAlearner(alpha=0.5, gamma=0.9, eps=0.5, eps_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play one game against the un-trained agent. This should be easy to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game = Game(agent)\n",
    "game.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the teacher agent. The teacher agent knows the optimal tic-tac-toe strategy. \"level\" specifies how often\n",
    "the agent will make the optimal move vs. a randomly-selected move (i.e., it is the probability of optimal move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = Teacher(level=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teach the SARSA agent via 50000 episodes (games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 100000\n",
    "for i in range(episodes):\n",
    "    game = Game(agent, teacher=teacher)\n",
    "    game.start()\n",
    "    if (i+1) % 5000 == 0:\n",
    "        print(\"Games played: %i\" % (i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize cumulative reward vs. episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agent_reward(rewards):\n",
    "    \"\"\" Function to plot agent's accumulated reward vs. episode \"\"\"\n",
    "    plt.plot(np.cumsum(rewards))\n",
    "    plt.title('Cumulative Reward vs. Time')\n",
    "    plt.ylabel('Cumulative Reward')\n",
    "    plt.xlabel('Time (# of actions)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agent_reward(agent.rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try playing the agent again, post-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent.eps = 0. # agent always takes greedy strategy\n",
    "game = Game(agent)\n",
    "game.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, repeat with Q-learning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "agent_q = Qlearner(alpha=0.5, gamma=0.9, eps=0.5, eps_decay=1e-5)\n",
    "episodes = 100000\n",
    "for i in range(episodes):\n",
    "    game = Game(agent_q, teacher=teacher)\n",
    "    game.start()\n",
    "    if (i+1) % 5000 == 0:\n",
    "        print(\"Games played: %i\" % (i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_agent_reward(agent_q.rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing the agent, post-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.eps = 0. # agent always takes greedy strategy\n",
    "game = Game(agent)\n",
    "game.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
